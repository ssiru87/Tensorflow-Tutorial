{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "* 주의 : 현재 최신 버전의 tensorflow 를 돌리기 위해서는 python 3.5 필요. 3.6에서는 안돌아감. (최신 기준: 11월 20일. tensorflow version: tensorflow-1.4.0-cp35-cp35m-macosx_10_11_x86_64.whl)\n",
    "```\n",
    "\n",
    "# CNN (Convolution Neural Network, 합성곱 신경망)\n",
    "\n",
    "- 대부분 이미지 처리에 활용\n",
    "- \"텐서플로 첫걸음\" 5장 참고\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 손글씨 이미지 인식 문제\n",
    "\n",
    "- MNIST 손글씨 이미지 예시: \n",
    "![title](images/mnist_plot.png)\n",
    "    \n",
    "- 각 data는 28 X 28 픽셀로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 00. MNIST 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 텐서플로 플레이스 홀더 정의\n",
    "\n",
    "- 텐서플로 플레이스 홀더 (tensorflow placeholder): 심볼릭 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 02. 입력 데이터 재 정의\n",
    "\n",
    "* 4D tensor로 재 정의. ? X Width X Height X Color channel (여기서는 흑백이라 -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_image=\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "print (\"x_image=\")\n",
    "print (x_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱 신경망\n",
    "\n",
    "![title](images/cnn_overview.png)\n",
    "    \n",
    "- 주요 목적: 테두리, 선, 색 등 이미지의 시각적 특징(characteristic)이나 특성(feature)을 감지\n",
    "- 입력 계층 (input layer)과 은닉 계층(hidden layer)에 의해 처리됨\n",
    "\n",
    "- 입력 뉴런의 작은 일부 영역만 첫 은닉 계층의 한 뉴런과 연결. (NOT FULLY connected)\n",
    "\n",
    "- 예를 들어 5x5  영역이 한 뉴런과 연결된다면,\n",
    "    - 28x28 을 훑기 위해서는 5x5 윈도우가 총 24x24개 필요\n",
    "\n",
    "- Stride (스트라이드): 한 번에 얼만큼의 윈도우를 움직일 지 결정하는 매개변수\n",
    "- Padding (패딩) : 이미지 바깥까지 윈도우가 이동하도록 허용할 때, 채울 테두리 크기 (넘어가는 값은 0 혹은 임의의 값.) \n",
    "\n",
    "- 합성곱 신경망에서는 y=Wx+b 에서, 은닉 계층의 모든 뉴런이 W와 b를 공유함\n",
    "- kernel (filter, 커널 / 필터) : W, b\n",
    "    - 고유한 특징을 찾는데 사용.\n",
    "    - 하나의 커널은 이미지에서 한 종류의 특징만을 감지 (/ 혹은 | 등)\n",
    "        - 커널로 특징맵 (feature map)을 만든다\n",
    "    \n",
    "- 합성곱 계층 (convolution layer): 특징맵 집합\n",
    "\n",
    "- 풀링 계층 (pooling layer): 합성곱 계층에 따라오는 것\n",
    "    - 합성곱 계층의 출력 값을 단순하게 압축하고, 합성곱 계층에서 생산한 정보를 컴팩트한 버전으로 만들어줌\n",
    "    - 28x28 인풋을 5x5 윈도우로 훑으면 나오는 24x24 합성곱 결과를 2x2 영역으로 분할(max pooling) 하면 12x12 \n",
    "    - 아래 코드에서는 padding 때문에 28x28 -> 28x28 (by padding) -> 14x14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# b\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer : stride(슬라이딩 윈도우 수) = 1, padding = SAME(패딩 방식중 하나)\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# pooling 방식은 max pooling: 2x2 영역에서 가장 큰 값 선택\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32]) # window가 5x5, 32개 필터(feature)\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수로 ReLU (Rectified Linear Unit) 사용: max(0, x) 리턴\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (h_pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 합성곱 계층. 예시를 위해 5x5 윈도우에 64개 필터로\n",
    "# 이전 계층의 출력값을 받아야 해서 세번째 값이 32\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 14x14 였던 h_pool1 에서 stride 1 적용 후 pooling 했기 때문에 7x7\n",
    "print (h_pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 연결 계층에 연결하기 위해 1024개의 뉴런 사용\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) #h_pool2의 7x7 크기의 64개 필터, 임의로 설정한 1024개의 뉴런\n",
    "b_fc1 = bias_variable([1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor to vector\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (h_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout : 매개변수 줄이기 (overfitting 방지)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\") #뉴런이 dropout 되지 않을 확률 저장\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # dropout 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_1/mul:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (h_fc1_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마지막으로, 모델에 소프트맥스 계층 추가\n",
    "\n",
    "* 여러 클래스로 데이터를 분류하고 싶을 때, sigmoid 함수의 일반화된 형태인 softmax 함수를 사용함\n",
    "\n",
    "* 소프트맥스: \n",
    "$$evidence_i=\\sum_{j} W_{i,j}x_j + b_i$$\n",
    "\n",
    "$$y = softmax(evidence)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴런 수 1024, 숫자 0~9 클래스 10개\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 평가\n",
    "# 이전까지 우리는 아무것도 돌리지 않았습니다. '설정' 만 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리는 여전히 아무것도 돌리지 않음. '선언'의 향연"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jiyeonjang/Git/personal/tensorflow_tutorial/env/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0 : training accuracy 0.1\n",
      "step 100 : training accuracy 0.87\n",
      "step 200 : training accuracy 0.89\n",
      "step 300 : training accuracy 0.96\n",
      "step 400 : training accuracy 0.93\n",
      "step 500 : training accuracy 0.97\n",
      "step 600 : training accuracy 0.95\n",
      "step 700 : training accuracy 0.96\n",
      "step 800 : training accuracy 0.93\n",
      "step 900 : training accuracy 0.96\n",
      "test accuracy: 0.9717\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() # 텐서플로우의 시작을 알림\n",
    "sess.run(tf.initialize_all_variables()) # 드디어 돌림\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x:batch[0], y_:batch[1], keep_prob:1.0})\n",
    "        print (\"step %d : training accuracy %g\" % (i, train_accuracy))\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_:batch[1], keep_prob:0.5})\n",
    "\n",
    "print (\"test accuracy: %g\" % sess.run(accuracy, feed_dict={x: mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "(1000번까지 돌리면 날라갈것 같아서...)\n",
    "\n",
    "![title](images/conv_result.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고\n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/conv2d\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
